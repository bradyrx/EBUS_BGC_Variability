{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Historical Components Vis\n",
      "This was first created on September 7th, 2017 for a group meeting talk with the Karnauskas/Lovenduski group meetings. The purpose is to make an illustrative visual (or series of visuals) to look at each component of the historical FG_CO2 time series so that folks know what I am actually characterizing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import xarray as xr\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "plt.style.use('ocn-clim')\n",
      "\n",
      "import esmtools as et\n",
      "\n",
      "# Stats\n",
      "from scipy import stats\n",
      "import numpy.polynomial.polynomial as poly"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "EBU = 'CalCS'\n",
      "VAR = 'FG_CO2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Temp MK Trend Test.\n",
      "Can't seem to install directly with pip.\n",
      "Got from : https://up-rs-esp.github.io/mkt/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy.special import ndtri, ndtr\n",
      "import sys\n",
      "\n",
      "\n",
      "def test(t, x, eps=None, alpha=None, Ha=None):\n",
      "    \"\"\"\n",
      "    Runs the Mann-Kendall test for trend in time series data.\n",
      "    Parameters\n",
      "    ----------\n",
      "    t : 1D numpy.ndarray\n",
      "        array of the time points of measurements\n",
      "    x : 1D numpy.ndarray\n",
      "        array containing the measurements corresponding to entries of 't'\n",
      "    eps : scalar, float, greater than zero\n",
      "        least count error of measurements which help determine ties in the data\n",
      "    alpha : scalar, float, greater than zero\n",
      "        significance level of the statistical test (Type I error)\n",
      "    Ha : string, options include 'up', 'down', 'upordown'\n",
      "        type of test: one-sided ('up' or 'down') or two-sided ('updown')\n",
      "    Returns\n",
      "    -------\n",
      "    MK : string\n",
      "        result of the statistical test indicating whether or not to accept hte\n",
      "        alternative hypothesis 'Ha'\n",
      "    m : scalar, float\n",
      "        slope of the linear fit to the data\n",
      "    c : scalar, float\n",
      "        intercept of the linear fit to the data\n",
      "    p : scalar, float, greater than zero\n",
      "        p-value of the obtained Z-score statistic for the Mann-Kendall test\n",
      "    Raises\n",
      "    ------\n",
      "    AssertionError : error\n",
      "                    least count error of measurements 'eps' is not given\n",
      "    AssertionError : error\n",
      "                    significance level of test 'alpha' is not given\n",
      "    AssertionError : error\n",
      "                    alternative hypothesis 'Ha' is not given\n",
      "    \"\"\"\n",
      "    # assert a least count for the measurements x\n",
      "    assert eps, \"Please provide least count error for measurements 'x'\"\n",
      "    assert alpha, \"Please provide significance level 'alpha' for the test\"\n",
      "    assert Ha, \"Please provide the alternative hypothesis 'Ha'\"\n",
      "\n",
      "    # estimate sign of all possible (n(n-1)) / 2 differences\n",
      "    n = len(t)\n",
      "    sgn = np.zeros((n, n), dtype=\"int\")\n",
      "    for i in range(n):\n",
      "        tmp = x - x[i]\n",
      "        tmp[np.where(np.fabs(tmp) <= eps)] = 0.\n",
      "        sgn[i] = np.sign(tmp)\n",
      "\n",
      "    # estimate mean of the sign of all possible differences\n",
      "    S = sgn[np.triu_indices(n, k=1)].sum()\n",
      "\n",
      "    # estimate variance of the sign of all possible differences\n",
      "    # 1. Determine no. of tie groups 'p' and no. of ties in each group 'q'\n",
      "    np.fill_diagonal(sgn, eps * 1E6)\n",
      "    i, j = np.where(sgn == 0.)\n",
      "    ties = np.unique(x[i])\n",
      "    p = len(ties)\n",
      "    q = np.zeros(len(ties), dtype=\"int\")\n",
      "    for k in range(p):\n",
      "        idx =  np.where(np.fabs(x - ties[k]) < eps)[0]\n",
      "        q[k] = len(idx)\n",
      "    # 2. Determine the two terms in the variance calculation\n",
      "    term1 = n * (n - 1) * (2 * n + 5)\n",
      "    term2 = (q * (q - 1) * (2 * q + 5)).sum()\n",
      "    # 3. estimate variance\n",
      "    varS = float(term1 - term2) / 18.\n",
      "\n",
      "    # Compute the Z-score based on above estimated mean and variance\n",
      "    if S > eps:\n",
      "        Zmk = (S - 1) / np.sqrt(varS)\n",
      "    elif np.fabs(S) <= eps:\n",
      "        Zmk = 0.\n",
      "    elif S < -eps:\n",
      "        Zmk = (S + 1) / np.sqrt(varS)\n",
      "\n",
      "    # compute test based on given 'alpha' and alternative hypothesis\n",
      "    # note: for all the following cases, the null hypothesis Ho is:\n",
      "    # Ho := there is no monotonic trend\n",
      "    # \n",
      "    # Ha := There is an upward monotonic trend\n",
      "    if Ha == \"up\":\n",
      "        Z_ = ndtri(1. - alpha)\n",
      "        if Zmk >= Z_:\n",
      "            MK = \"accept Ha := upward trend\"\n",
      "        else:\n",
      "            MK = \"reject Ha := upward trend\"\n",
      "    # Ha := There is a downward monotonic trend\n",
      "    elif Ha == \"down\":\n",
      "        Z_ = ndtri(1. - alpha)\n",
      "        if Zmk <= -Z_:\n",
      "            MK = \"accept Ha := downward trend\"\n",
      "        else:\n",
      "            MK = \"reject Ha := downward trend\"\n",
      "    # Ha := There is an upward OR downward monotonic trend\n",
      "    elif Ha == \"upordown\":\n",
      "        Z_ = ndtri(1. - alpha / 2.)\n",
      "        if np.fabs(Zmk) >= Z_:\n",
      "            MK = \"accept Ha := upward OR downward trend\"\n",
      "        else:\n",
      "            MK = \"reject Ha := upward OR downward trend\"\n",
      "\n",
      "    # ----------\n",
      "    # AS A BONUS\n",
      "    # ----------\n",
      "    # estimate the slope and intercept of the line\n",
      "    m = np.corrcoef(t, x)[0, 1] * (np.std(x) / np.std(t))\n",
      "    c = np.mean(x) - m * np.mean(t)\n",
      "\n",
      "    # ----------\n",
      "    # AS A BONUS\n",
      "    # ----------\n",
      "    # estimate the p-value for the obtained Z-score Zmk\n",
      "    if S > eps:\n",
      "        if Ha == \"up\":\n",
      "            p = 1. - ndtr(Zmk)\n",
      "        elif Ha == \"down\":\n",
      "            p = ndtr(Zmk)\n",
      "        elif Ha == \"upordown\":\n",
      "            p = 0.5 * (1. - ndtr(Zmk))\n",
      "    elif np.fabs(S) <= eps:\n",
      "        p = 0.5\n",
      "    elif S < -eps:\n",
      "        if Ha == \"up\":\n",
      "            p = 1. - ndtr(Zmk)\n",
      "        elif Ha == \"down\":\n",
      "            p = ndtr(Zmk)\n",
      "        elif Ha == \"upordown\":\n",
      "            p = 0.5 * (ndtr(Zmk))\n",
      "    return MK, m, c, p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load in Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_in_filtered_data(VAR, EBU, AW=True):\n",
      "    \"\"\"\n",
      "    Loads in the netCDF files for the ensemble mean and residuals for any inputted variable\n",
      "    and returns an xarray dataset for the forced signal, residuals, and the total time series\n",
      "    (simply the sum of the two previous components).\n",
      "    \"\"\"\n",
      "    fileDir = '/glade/work/rbrady/EBUS_BGC_Variability/' + VAR + '/' + EBU + '/filtered_output/'\n",
      "    if AW == True:\n",
      "        ds_forced = xr.open_dataset(fileDir + EBU.lower() + '-' + VAR + '-forced-signal-AW-chavez-800km.nc')\n",
      "        ds_residuals = xr.open_dataset(fileDir + EBU.lower() + '-' + VAR + '-residuals-AW-chavez-800km.nc')\n",
      "    if AW == False:\n",
      "        ds_forced = xr.open_dataset(fileDir + EBU.lower() + '-' + VAR + '-forced-signal-chavez-800km.nc')\n",
      "        ds_residuals = xr.open_dataset(fileDir + EBU.lower() + '-' + VAR + '-residuals-chavez-800km.nc')\n",
      "    ds_total = ds_forced + ds_residuals\n",
      "    return ds_forced, ds_residuals, ds_total"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ant_mean, ant_resid, ant_total = load_in_filtered_data('FG_ANT_CO2', EBU)\n",
      "con_mean, con_resid, con_total = load_in_filtered_data('FG_CO2', EBU)\n",
      "nat_mean, nat_resid, nat_total = load_in_filtered_data('FG_ALT_CO2', EBU)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Compute Each Component\n",
      "We have four components to visualize here:\n",
      "\n",
      "1. The historical mean state of the system (level)\n",
      "2. The seasonal cycle (ensemble mean - trend)\n",
      "3. The trend (linear trend)\n",
      "4. The residuals"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For clarity:\n",
      "\n",
      "The red line *should* drift away from the black line. This simply represents the anthropogenic sink (by fitting the ensemble mean with a 4th order fit). The black line is plotted to only show the seasonal cycle component, so it should be stationary. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = con_total['time'].values\n",
      "ensemble_mean = con_mean[VAR + '_AW'].values\n",
      "\n",
      "# Break down all components\n",
      "x = np.arange(0, len(t), 1)\n",
      "coefs = poly.polyfit(x, ensemble_mean, 1)\n",
      "line_fit = poly.polyval(x, coefs) # This is the trend portion\n",
      "\n",
      "# Quantifable trend (first order)\n",
      "slope, _, _, _, _ = stats.linregress(x, ensemble_mean)\n",
      "slope = slope * len(t)\n",
      "\n",
      "# I think the \"level\" or historical state of the system should clearly\n",
      "# not be the mean of the time series due to the trend. You could either\n",
      "# just look at the intercept of the linear regression, or the intercept\n",
      "# of a 4th order polynomial.\n",
      "b = coefs[0]\n",
      "level = np.zeros(len(t))\n",
      "level[:] = b\n",
      "\n",
      "# Seasonal cycle needs to be detrended, but then scaled back up to the intercept\n",
      "seasonal_cycle = ensemble_mean "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Quantification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean = con_total[VAR + '_AW'].mean().values.round(2)\n",
      "print(\"Mean: \" + str(mean) + ' (mol/m2/yr)')\n",
      "\n",
      "print(\"Intercept: \" + str(b.round(2)))\n",
      "\n",
      "seasonal = con_mean.apply(et.ufunc.seasonal_magnitude)[VAR + \"_AW\"].values.round(2)\n",
      "print(\"Seasonal: \" + str(seasonal) + ' (mol/m2/yr)')\n",
      "\n",
      "internal = con_resid[VAR + '_AW'].std('time').mean('ensemble').values.round(2)\n",
      "print(\"Internal: \" + str(internal) + ' (mol/m2/yr)')\n",
      "\n",
      "print(\"Trend: \" + str(slope.round(2)) + '(mol/m2/yr/96yr)')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Test significance of trend."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tt = np.arange(0,len(con_mean.time))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MK, m, c, p = test(tt, con_mean[VAR + \"_AW\"].values, eps=1E-3, alpha=0.05, Ha='down')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MK"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Slope over full time period: \" + str((m*1152).round(3)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Master Plot with Everything Included"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(18,4))\n",
      "ax = plt.subplot(111)\n",
      "\n",
      "# RESIDUALS\n",
      "#for idx in np.arange(0, 34, 1):\n",
      "#    data = con_total['FG_CO2_AW'][:, idx].values\n",
      "#    plt.plot(t, data, color='#d3d3d3', linewidth=1)\n",
      "\n",
      "# This approach makes it easier to work with in Illustrator.\n",
      "data_min = con_total[VAR + \"_AW\"].max('ensemble')\n",
      "data_max = con_total[VAR + \"_AW\"].min('ensemble')\n",
      "plt.fill_between(t, data_min, data_max, color='#d3d3d3', label='Internal Variability')\n",
      "\n",
      "# SEASONALITY\n",
      "plt.plot(t, seasonal_cycle, linewidth=2, color='k', label='Seasonal Cycle')\n",
      "\n",
      "# TREND\n",
      "plt.plot(t, line_fit, color='r', linewidth=2, label='Anthropogenic Trend')\n",
      "\n",
      "# LEVEL\n",
      "#plt.plot(t, level, color='k', linewidth=2, linestyle='--')\n",
      "\n",
      "# Zero line    \n",
      "plt.plot(t, np.zeros(len(t)), color='k', linewidth=1)\n",
      "ax.set(xlim=['1920', '2015'])\n",
      "ax.set(ylim=[-4, 12])\n",
      "\n",
      "# Aesthetics\n",
      "ax.set_title('Benguela Current Historical F$_{\\mathrm{CO}_{2}}$')\n",
      "ax.set_xlabel('Model Years')\n",
      "ax.set_ylabel('Sea-Air CO$_{2}$ Flux' + '\\n' +  '[mol/m$^{2}$/yr]')\n",
      "\n",
      "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
      "\n",
      "# Save figure.\n",
      "#et.vis.savefig('benguela_legend', extension='.eps', dpi=300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Just mean seasonal component "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Taken from esmtools seasonal_magnitude function\n",
      "def seasonal_cycle(ds):\n",
      "    x = np.arange(0, len(ds.time), 1)\n",
      "    coefs = poly.polyfit(x, ds, 4)\n",
      "    poly_fit = poly.polyval(x, coefs)\n",
      "    seasonality = (ds - poly_fit)\n",
      "    climatology = ds.groupby('time.month').mean()\n",
      "    return climatology"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seasonal = con_mean.apply(seasonal_cycle)['FG_CO2_AW']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, ax = plt.subplots()\n",
      "\n",
      "# Seasonal Cycle\n",
      "ax.plot(seasonal.month, seasonal, color='k')\n",
      "\n",
      "# Internal variability magnitude\n",
      "internal = con_resid['FG_CO2_AW'].groupby('time.month').std('time').mean('ensemble')\n",
      "ax.bar(internal.month, internal, color='#d3d3d3', edgecolor='#d3d3d3')\n",
      "\n",
      "#####\n",
      "ax.set_xticks(np.arange(1,13,2))\n",
      "ax.set_xticklabels(['J','M','M','J','S','N'])\n",
      "ax.set_ylim([-1.5,5])\n",
      "#et.vis.savefig('HumCS_seasonal', extension='.eps', dpi=300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}