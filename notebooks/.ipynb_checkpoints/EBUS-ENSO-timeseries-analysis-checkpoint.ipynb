{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBUS-ENSO Timeseries Analysis\n",
    "- Taking output from the EBUS_extraction.py script to analyze it in coordination with Adam Phillip's CVDP output (starting with Nino 3.4)\n",
    "- First step is to work with CCS, since that's a comfortable area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UNIX-style globbing\n",
    "import glob\n",
    "\n",
    "# Numerics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "\n",
    "from pylab import *\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import scipy.fftpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "- For visibility in the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "colors = {\n",
    "    'CalCS': '#80b1d3',\n",
    "    'HumCS': '#fb8072',\n",
    "    'CanCS': '#fdb462',\n",
    "    'BenCS': '#bc80bd'\n",
    "}\n",
    "ens = ['001', '002', '009', '010', '011',\n",
    "       '012', '013', '014', '015', '016',\n",
    "       '017', '018', '019', '020', '021',\n",
    "       '022', '023', '024', '025', '026',\n",
    "       '027', '028', '029', '030', '031',\n",
    "       '032', '033', '034', '035', '101',\n",
    "       '102', '103', '104', '105']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detrend_nino(x):\n",
    "    return signal.detrend(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_correlations(carbonData, climateData):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(climateData, carbonData)\n",
    "    return slope, r_value, r_value**2, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_series(x, length=12):\n",
    "    return pd.rolling_mean(x, length, center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_ensemble_dim(ds, x):\n",
    "    ds[x] = (('nlat','nlon'), ds[x][0])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_map(ax, lon, lat, lat1=np.nan, lat2=np.nan,\n",
    "              lon1=np.nan, lon2=np.nan):\n",
    "    if np.isnan(lat1):\n",
    "        lat1=np.nanmin(lat)\n",
    "        lat2=np.nanmax(lat)\n",
    "        lon1=np.nanmin(lon)\n",
    "        lon2=np.nanmax(lon)\n",
    "    m = Basemap(projection='eqdc',\n",
    "                lat_0=(lat1 + lat2)/2,\n",
    "                lon_0=(lon1 + lon2)/2,\n",
    "                llcrnrlon=lon1,\n",
    "                urcrnrlon=lon2,\n",
    "                llcrnrlat=lat1,\n",
    "                urcrnrlat=lat2,\n",
    "                resolution='c')\n",
    "    m.drawcoastlines()\n",
    "    #m.fillcontinents(color='black')\n",
    "    m.drawmapboundary(fill_color='white')\n",
    "    m.drawparallels(np.arange(np.floor(np.nanmin(lat)), \n",
    "                              np.ceil(np.nanmax(lat)), 3),\n",
    "                   labels=[True,False,False,False], size='x-large')\n",
    "    m.drawmeridians(np.arange(np.floor(np.nanmin(lon)), \n",
    "                              np.ceil(np.nanmax(lon)), 3),\n",
    "                   labels=[False, False, False, True], size='x-large')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chavez_bounds(x):\n",
    "    if x == \"CalCS\":\n",
    "        lat1 = 34\n",
    "        lat2 = 44\n",
    "    elif x == \"CanCS\":\n",
    "        lat1 = 12\n",
    "        lat2 = 22\n",
    "    elif x == \"BenCS\":\n",
    "        lat1 = -28\n",
    "        lat2 = -18\n",
    "    elif x == \"HumCS\":\n",
    "        lat1 = -16\n",
    "        lat2 = -6\n",
    "    else:\n",
    "        raise ValueError('\\n' + 'Must select from the following EBUS strings:'\n",
    "                         + '\\n' + 'CalCS' + '\\n' + 'CanCS' + '\\n' + 'BenCS' +\n",
    "                         '\\n' + 'HumCS')\n",
    "    return lat1, lat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Region \n",
    "(If wanting to investigate stuff without residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EBU = 'HumCS'\n",
    "VAR = 'pCO2SURF'\n",
    "OFFSHORE = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileDir = '/glade/u/home/rbrady/work/EBUS_BGC_Variability/' + VAR + '/' + EBU + '/'\n",
    "ds = xr.open_mfdataset(fileDir + '*.nc', concat_dim='ensemble')\n",
    "ds = drop_ensemble_dim(ds, 'DXT')\n",
    "ds = drop_ensemble_dim(ds, 'TAREA')\n",
    "ds = drop_ensemble_dim(ds, 'REGION_MASK')\n",
    "ds = drop_ensemble_dim(ds, 'TLAT')\n",
    "if EBU != \"HumCS\":\n",
    "    ds = drop_ensemble_dim(ds, 'TLONG')\n",
    "del ds['DYT']\n",
    "del ds['ANGLET']\n",
    "ds['DXT'] = ds['DXT'] / 100 / 1000\n",
    "lat1, lat2 = chavez_bounds(EBU)\n",
    "ds = ds.where(ds['TLAT'] >= lat1).where(ds['TLAT'] <= lat2)\n",
    "data = ds[VAR][0,0]\n",
    "data = np.ma.array(data, mask=np.isnan(data))\n",
    "dxt_dat = ds['DXT']\n",
    "dxt_dat = np.ma.array(dxt_dat, mask=np.isnan(data))\n",
    "ds['DXT'] = (('nlat','nlon'), dxt_dat)\n",
    "regmask = ds['REGION_MASK']\n",
    "counter = 0\n",
    "for row in regmask:\n",
    "    conditional = 0 in row.values\n",
    "    if conditional == False:\n",
    "        ds['DXT'][counter, :] = np.nan\n",
    "    counter += 1\n",
    "x = ds['DXT'].values\n",
    "x = np.ma.array(x, mask=np.isnan(x))\n",
    "dxt_cum = np.cumsum(x[:, ::-1], axis=1)[:, ::-1]\n",
    "ds['DXT_Cum'] = (('nlat', 'nlon'), dxt_cum)\n",
    "ds = ds.where(ds['DXT_Cum'] <= OFFSHORE)\n",
    "ds = ((ds * ds['TAREA']).sum(dim='nlat').sum(dim='nlon'))/ds['TAREA'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Residuals and Area Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "EBU = 'HumCS'\n",
    "VAR = 'pCO2SURF'\n",
    "fileDir = '/glade/u/home/rbrady/work/EBUS_BGC_Variability/' + VAR + '/' + EBU + '/filtered_residuals/'\n",
    "ds_var = xr.open_dataset(fileDir + EBU.lower() + '-' + VAR + '-residuals-chavez-800km.nc')\n",
    "ds_var = ((ds_var * ds_var['TAREA']).sum(dim='nlat').sum(dim='nlon'))/ds_var['TAREA'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Study Region\n",
    "Are we in the right area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert all non-nan values to a constant to just plot the domain as one color.\n",
    "data = np.asarray(ds_residuals[VAR][0].mean(dim='time'))\n",
    "mask = ~np.isnan(data)\n",
    "data[mask] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lon = ds['TLONG'].values\n",
    "lat = ds['TLAT'].values\n",
    "#data = ds['FG_CO2'][0].mean(dim='time')\n",
    "data = np.ma.array(data, mask=np.isnan(data))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "ax = fig.add_subplot(111)\n",
    "m = setup_map(ax,lon,lat)\n",
    "m.drawcountries()\n",
    "#m.drawstates()\n",
    "m.pcolor(lon, lat, data, vmin=0, vmax = 1500,\n",
    "          latlon=True, cmap=\"Blues\", edgecolors='white')\n",
    "plt.title('Humboldt Current Study Site', size=24)\n",
    "#plt.savefig('canary-current-study-site.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Series\n",
    "Create a plot with original unfiltered time series and the annual smoothing over top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ds_residuals[VAR][0].values\n",
    "smoothed_data = smooth_series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,4))\n",
    "t = ds_residuals['time'].values\n",
    "plt.plot(t, data, color=colors[EBU])\n",
    "plt.plot(t, smoothed_data, '-k')\n",
    "plt.ylabel('pCO$_{2}$ ($\\mu$atm)', size=20)\n",
    "plt.title('Simulation 001' + EBU + ' ' + VAR + ' ' + 'Anomaly, Annual Smoothing (1920-2015)', size=25)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "#plt.savefig('bencs-filtered-fgco2-series-example.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ds_residuals[0].values\n",
    "hann = np.hanning(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.fft.fft(hann*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(Y)/2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 1.0/(30*24*60*60) # Sampled once every month\n",
    "X = np.linspace(0, T/2, N, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,4))\n",
    "plt.plot(X, 2.0*np.abs(Y[:N])/N, color='r')\n",
    "plt.xlabel('Frequency ($Hz$)', size='x-large')\n",
    "plt.title('FFT of HCS FG_CO2 for Simulation 001', size='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "#plt.savefig('fft-HCS-001-frequencyHz.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same plot but in Period\n",
    "Xp = 1.0/X # Inverse to seconds\n",
    "Xpd= Xp/(60.0 * 60.0 * 24) # in days\n",
    "fig = plt.figure(figsize=(18,4))\n",
    "plt.plot(Xpd, 2.0*np.abs(Y[:N])/N, color='r')\n",
    "plt.xlabel('Frequency ($Hz$)', size='x-large')\n",
    "plt.title('FFT of HCS FG_CO2 for Simulation 001', size='x-large')\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.xlim([0, 365])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVDP: Adam Phillips\n",
    "- Messing with the climate diagnostics that Adam Phillips provides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileDir = '/glade/p/work/rbrady/cesmLE_CVDP/extracted_vars/'\n",
    "ds_cvdp = xr.open_mfdataset(fileDir + '*.nc', decode_times=False, concat_dim='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_cvdp = ds_cvdp.rename({'npo_pc_mon': 'npo', \n",
    "                          'pdo_timeseries_mon': 'pdo',\n",
    "                          'sam_pc_mon': 'sam',\n",
    "                          'ipo_timeseries_mon': 'ipo',\n",
    "                          'amo_timeseries_mon': 'amo',\n",
    "                          'nao_pc_mon': 'nao'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = pd.date_range('1920-01', '2016-01', freq='M')\n",
    "ds_cvdp['time'] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_cvdp = ds_cvdp.apply(detrend_nino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,4))\n",
    "nino_dat = ds_cvdp['nino34'][0]\n",
    "t = nino_dat.time.values\n",
    "pos = nino_dat.where(nino_dat > 0)\n",
    "neg = nino_dat.where(nino_dat < 0)\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.bar(t, pos, color='none', edgecolor='red')\n",
    "ax1.bar(t, neg, color='none', edgecolor='blue')\n",
    "ax1.set_ylabel('Nino 3.4 Index')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(t, smoothed_data, '-k')\n",
    "ax2.set_ylabel('FG_CO2 Anomalies (mol/m2/yr)')\n",
    "\n",
    "ax1.grid('off')\n",
    "ax2.grid('off')\n",
    "\n",
    "plt.title('Simulation 001 Nino3.4 Index + Smoothed FG_CO2 Anomalies')\n",
    "#fig.savefig('ccs-smoothed-fgco2-and-nino34-plot.png')\n",
    "#fig.savefig('ccs-smoothed-fgco2-and-nino34-plot.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Correlation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_correlate(idx, ds_residuals, ds_cvdp, climvar):\n",
    "    print('Working on {}...').format(idx)\n",
    "    data = ds_residuals[idx]\n",
    "    data = smooth_series(data.values)\n",
    "    data = data[11::]\n",
    "    clim_data = ds_cvdp[climvar][idx]\n",
    "    clim_data = clim_data[11::]\n",
    "    return data, clim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "climvar = 'sam'\n",
    "\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "st = fig.suptitle(\"BenCS SAM vs FG_CO2 Cross-Correlations\" + \"\\n\" + \"SAM Leads to the Left of Zero\", fontsize=\"x-large\")\n",
    "for idx in range(34):\n",
    "    data, clim_data = cross_correlate(idx, ds_residuals, ds_cvdp, climvar)\n",
    "    ax = fig.add_subplot(6, 6, idx+1)\n",
    "    arr = plt.xcorr(clim_data, data, maxlags=12)\n",
    "    axes = plt.gca()\n",
    "    ymin, ymax = axes.get_ylim()\n",
    "    plt.text(-11.75, ymax-0.025, \"S\" + ens[idx])\n",
    "    plt.xlim([-12, 12])\n",
    "    # Show zero boundary\n",
    "    zero_val = arr[1][12]\n",
    "    plt.plot([0,0], [0,zero_val], '-r')\n",
    "fig.tight_layout()\n",
    "# shift subplots down:\n",
    "st.set_y(0.95)\n",
    "fig.subplots_adjust(top=0.90)\n",
    "plt.savefig(\"SAM_FGCO2_cross-correlation_BenCS.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
